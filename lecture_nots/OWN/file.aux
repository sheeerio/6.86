\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Linear Classifiers and Generalizations}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Intro}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Linear Classifier and Perceptron}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition:}{2}{section*.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Perceptron Algorithm}}{2}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Hinge Loss, Margin boundaries}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A little insight to Generalization}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Error Decomposition}{3}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Gradient Descent: Geometrically Revisited}{3}{subsubsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Stochastic Gradient descent}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{4}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}A look at Cross Validation}{4}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Nonlinear Classifications and Linear Regression}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Linear Regression}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{5}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Objective}{5}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mistakes}{5}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{NOTE!!}{5}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Gradient-based approach}{5}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Gradient Descent}}{6}{algorithm.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Closed form solution}{6}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Regularization}{7}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Ridge Gradient Descent}}{7}{algorithm.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Equivalance of regularization to a Gaussian Prior on Weights}{7}{subsubsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Nonlinear Classification}{8}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why not feature vectors?}{8}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Kernels}{9}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Recall Perceptron (The kernel Perceptron Algorithm)}}{9}{algorithm.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Composition Rules}{9}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Radial Basis Kernel}{9}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Neural Networks}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feedforward Neural Nets}{10}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learning neural networks}{11}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Back-propagation}{11}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Proof for the derivative of the hyberbolic tangent function}{11}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{11}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Side Note}{12}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Recurrent Neural Networks}{12}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Encoding}{12}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{rnn}{{3.2.1}{12}{Encoding}{subsubsection.3.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Note}{13}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Gating and LSTM}{13}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{13}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Markov Models}{13}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantage?}{14}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Convolution Neural Network}{14}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{14}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Reinforcement Learning}{14}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Reinforcement Learning I}{15}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RL Terminology}{15}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Utility Function}{15}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{15}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Policy}{16}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Bellman Equations}{16}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Value Iteration Algorithm}{16}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Estimating inputs for RL algorithm}{17}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model-based}{17}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model-free}{17}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Q-value iteration for RL}{17}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Exploration vs Exploitation}{18}{section*.43}\protected@file@percent }
\gdef \@abspage@last{18}
